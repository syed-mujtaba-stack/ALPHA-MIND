# ğŸš€ ALPHA MIND - Intelligent Hybrid AI Chatbot System

<div align="center">

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![React](https://img.shields.io/badge/React-18+-61DAFB.svg)](https://reactjs.org/)
[![Django](https://img.shields.io/badge/Django-4.0+-092E20.svg)](https://www.djangoproject.com/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-3178C6.svg)](https://www.typescriptlang.org/)

**A powerful hybrid AI chat platform that combines cloud AI models (via OpenRouter) with local/offline models (via liteLLM) for fast, cheap, and privacy-focused AI conversations.**

[ğŸ“– Documentation](#-documentation) â€¢ [ğŸš€ Getting Started](#-getting-started) â€¢ [ğŸ¯ Features](#-features) â€¢ [ğŸ—ï¸ Architecture](#ï¸-architecture)

</div>

---

## âœ¨ Features

### ğŸ¯ Core Features
- ğŸ”„ **Hybrid AI System**: Switch between cloud (OpenRouter) and local (liteLLM) models
- ğŸ¤– **Multiple AI Models**: GPT-4, Claude 3.5, Gemini, Llama, Grok, Deepseek, and local models
- âš¡ **Streaming Chat**: Real-time responses like ChatGPT
- ğŸ§  **Smart Routing**: Automatic fallback between cloud and local models
- ğŸ“ **File Analysis**: PDF, Image, Excel upload and analysis
- ğŸ’» **Code Assistant**: Bug fixing, code generation, project structure builder
- ğŸ‘¤ **User System**: Firebase Authentication with profiles and history
- ğŸŒ™ **Dark/Light Mode**: Modern UI with theme switching

### ğŸš€ Advanced Features
- ğŸ¤ **Voice Chat**: Speech â†’ Text & Text â†’ Speech
- ğŸ¨ **Image Generation**: AI-powered image creation
- ğŸ“„ **Document Summaries**: Smart document analysis
- ğŸ” **Web Search Mode**: Real-time web information
- ğŸ¤– **AI Agents**: Task automation

---

## ğŸ—ï¸ Architecture

```mermaid
graph TB
    A[React.js Frontend<br/>TypeScript + Tailwind] --> B[Firebase Authentication<br/>Frontend Login + ID Token]
    B --> C[Django Backend<br/>Token Verification + Route to AI Engine]
    C --> D[OpenRouter API<br/>Cloud Models]
    C --> E[liteLLM Local Gateway<br/>GPU/CPU Local Models]
    
    style A fill:#61DAFB,stroke:#333,stroke-width:2px
    style B fill:#FFCA28,stroke:#333,stroke-width:2px
    style C fill:#092E20,stroke:#333,stroke-width:2px
    style D fill:#4285F4,stroke:#333,stroke-width:2px
    style E fill:#FF6B6B,stroke:#333,stroke-width:2px
```

---

## ğŸ“ Project Structure

```
ALPHA MIND/
â”‚
â”œâ”€â”€ ğŸ¨ frontend/           # React.js + TypeScript + Tailwind
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/   # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ pages/        # Application pages
â”‚   â”‚   â”œâ”€â”€ hooks/        # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ utils/        # Utility functions
â”‚   â”‚   â””â”€â”€ types/        # TypeScript definitions
â”‚   â”œâ”€â”€ public/           # Static assets
â”‚   â””â”€â”€ package.json       # Dependencies
â”‚
â”œâ”€â”€ ğŸ—„ï¸ backend/            # Django REST Framework
â”‚   â”œâ”€â”€ alpha_mind/       # Django project settings
â”‚   â”œâ”€â”€ chat/             # Chat functionality
â”‚   â”œâ”€â”€ users/            # User management
â”‚   â”œâ”€â”€ files/            # File upload & analysis
â”‚   â”œâ”€â”€ gateway/          # AI model gateway
â”‚   â””â”€â”€ requirements.txt   # Python dependencies
â”‚
â”œâ”€â”€ ğŸ¤– ai_engine/          # FastAPI AI Engine
â”‚   â”œâ”€â”€ main.py           # FastAPI app
â”‚   â”œâ”€â”€ models.py         # Pydantic models
â”‚   â”œâ”€â”€ services.py       # AI services
â”‚   â”œâ”€â”€ providers.py      # AI providers
â”‚   â””â”€â”€ requirements.txt  # Python dependencies
â”‚
â”œâ”€â”€ ğŸ¦¾ local-llm/          # liteLLM Configuration
â”‚   â”œâ”€â”€ liteLLM.yaml      # Configuration file
â”‚   â”œâ”€â”€ models/           # Local model storage
â”‚   â””â”€â”€ scripts/          # Setup scripts
â”‚
â”œâ”€â”€ ğŸ“š docs/               # Documentation
â”‚   â”œâ”€â”€ api.md            # API documentation
â”‚   â”œâ”€â”€ deployment.md     # Deployment guide
â”‚   â””â”€â”€ setup.md          # Setup instructions
â”‚
â””â”€â”€ ğŸ“„ README.md           # This file
```

---

## ğŸ› ï¸ Tech Stack

### ğŸ¨ Frontend
- **React.js** with TypeScript
- **Tailwind CSS** for styling
- **Firebase** for authentication
- **Axios** for API calls
- **React Router** for navigation
- **Zustand** for state management
- **React Query** for data fetching

### ğŸ—„ï¸ Backend
- **Django** with REST Framework
- **Firebase Admin SDK** for token verification
- **OpenRouter API** for cloud models
- **liteLLM** for local models
- **Redis** for caching (optional)

### ğŸ¤– AI Engine
- **FastAPI** for AI model gateway
- **OpenAI** for API compatibility
- **litellm** for local model integration
- **transformers** for local models

---

## ğŸš€ Getting Started

### ğŸ“‹ Prerequisites
- Node.js 18+
- Python 3.9+
- Django 4.0+
- Firebase Project
- OpenRouter API Key
- GPU (for local models, optional)

### ğŸ”§ Installation

#### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/syed-mujtaba-stack/ALPHA-MIND.git
cd ALPHA-MIND
```

#### 2ï¸âƒ£ Frontend Setup
```bash
cd frontend
npm install
cp .env.example .env.local
# Add Firebase config to .env.local
npm run dev
```

#### 3ï¸âƒ£ Backend Setup
```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env
# Add API keys to .env
python manage.py migrate
python manage.py runserver
```

#### 4ï¸âƒ£ AI Engine Setup
```bash
cd ai_engine
pip install -r requirements.txt
cp .env.example .env
# Configure OpenRouter API key
uvicorn main:app --reload
```

#### 5ï¸âƒ£ Local Models Setup (Optional)
```bash
cd local-llm
pip install litellm
# Configure liteLLM.yaml
# Download local models
```

---

## ğŸ”§ Configuration

### ğŸŒ Environment Variables

#### ğŸ¨ Frontend (.env.local)
```env
VITE_FIREBASE_API_KEY=your_firebase_api_key
VITE_FIREBASE_AUTH_DOMAIN=your_project.firebaseapp.com
VITE_FIREBASE_PROJECT_ID=your_project_id
VITE_FIREBASE_MESSAGING_SENDER_ID=your_sender_id
VITE_FIREBASE_APP_ID=your_app_id
VITE_API_URL=http://localhost:8000
VITE_AI_ENGINE_URL=http://localhost:4000
```

#### ğŸ—„ï¸ Backend (.env)
```env
SECRET_KEY=your_django_secret_key
DEBUG=True
FIREBASE_PROJECT_ID=your_project_id
OPENROUTER_API_KEY=your_openrouter_key
LITELLM_HOST=http://localhost:4000
DATABASE_URL=sqlite:///db.sqlite3
```

#### ğŸ¤– AI Engine (.env)
```env
OPENROUTER_API_KEY=your_openrouter_api_key_here
LITELLM_HOST=http://localhost:4000
LITELLM_API_KEY=your_litellm_api_key_here
LOCAL_MODEL_PATH=./models
GPU_ENABLED=true
```

---

## ğŸ“– API Documentation

### ğŸ” Authentication
- `POST /api/auth/check/` - Verify Firebase token

### ğŸ’¬ Chat
- `POST /api/chat/send/` - Send chat message
- `GET /api/chat/history/<session_id>/` - Get chat history
- `POST /api/chat/save/` - Save conversation
- `GET /api/chat/sessions/` - List chat sessions

### ğŸ¤– Models
- `GET /api/models/list/` - List available models
- `POST /api/models/switch/` - Switch active model

### ğŸ“ Files
- `POST /api/files/upload/` - Upload file for analysis
- `POST /api/files/analyze/` - Analyze uploaded file
- `GET /api/files/list/` - List uploaded files

---

## ğŸ¯ Usage

1. **ğŸ” Sign up/login** with Firebase Authentication
2. **ğŸ¤– Choose your AI model** from the dropdown
3. **ğŸ’¬ Start chatting** with streaming responses
4. **ğŸ“ Upload files** for analysis (PDF, images, Excel)
5. **ğŸ’» Switch to code mode** for development assistance
6. **ğŸŒ Enable offline mode** for local model usage

---

## ğŸ¤ Contributing

1. **ğŸ´ Fork** the repository
2. **ğŸŒ¿ Create** a feature branch
3. **ğŸ’¾ Commit** your changes
4. **ğŸ“¤ Push** to the branch
5. **ğŸ”€ Open** a Pull Request

---

## ğŸ“Š Development Status

### âœ… Completed (Phase 1-2)
- [x] Project structure setup
- [x] Modern React frontend with shadcn/ui
- [x] Django backend with all apps
- [x] FastAPI AI Engine
- [x] Firebase Authentication integration
- [x] Real-time chat interface
- [x] Message history persistence

### ğŸš§ In Progress (Phase 3)
- [ ] OpenRouter API integration
- [ ] liteLLM local models setup
- [ ] Smart routing implementation
- [ ] Fallback mechanisms

### ğŸ“‹ Planned (Phase 4-5)
- [ ] File analysis features
- [ ] Voice chat functionality
- [ ] Advanced AI agents
- [ ] Deployment & testing

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **ğŸ¤– OpenRouter** for providing unified AI model access
- **ğŸ¦¾ liteLLM** for local model integration
- **ğŸ”¥ Firebase** for authentication services
- **ğŸ Django Team** for the excellent framework
- **âš¡ FastAPI** for modern API development

---

<div align="center">

**ğŸš€ Ready to start building the future of AI chatbots?**

[ğŸ“– Documentation](docs/) â€¢ [ğŸ› Report Bug](https://github.com/syed-mujtaba-stack/ALPHA-MIND/issues) â€¢ [ğŸ’¡ Feature Request](https://github.com/syed-mujtaba-stack/ALPHA-MIND/issues/new)

Built with â¤ï¸ by the **ALPHA MIND** team

</div>
